{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = open('Reclame.csv', 'w', newline='') #Cria e abre um arquivo no formato csv\n",
    "csv_writer = csv.writer(csv_file) #escrever linhas no csv\n",
    "csv_writer.writerow(['ID', 'Titulo', 'Reclamacao','Cidade','Data','status']) # coloca os títulos das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reclameaqui.com.br/empresa/itau/lista-reclamacoes/?pagina=1&produto=0000000000000914\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.reclameaqui.com.br' #cria uma variável com a url do site reclame aqui\n",
    "empresa = 'itau'\n",
    "produto = '0000000000000914'\n",
    "url_site = f'{base_url}/empresa/{empresa}/lista-reclamacoes/?pagina=1&produto={produto}' #extensão do site\n",
    "print (url_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = webdriver.Chrome() #abre o navegador Google Chrome\n",
    "ff.get(url_site) #abre o site\n",
    "sleep(3) #espera carregar a página por 3 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagina = bs(ff.page_source, 'html.parser')\n",
    "links = pagina.find('div', {'class': 'card-footer text-center'}).find_all('li', {'class=\"ng-binding'})\n",
    "links\n",
    "paginas =([link.text for link in links])\n",
    "paginas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_obj = bs(ff.page_source, 'html.parser') #iniciando o BeautifulSoup para analisar a página do reclame aqui\n",
    "boxe = bs_obj.find('div', {'class': 'content-loader'}) #encontrando a tag div que tenha a class \"content-loader)\"\n",
    "boxes = boxe.find_all('li', {'class': 'ng-scope'}) #encontra todos os tags li que tenham a class \"ng-scope\"\n",
    "href_links = [box.find('a').get('href') for box in boxes] #pega todos as tags a>href dentro da variavel boxes \n",
    "page_links = [f'{base_url}{link}' for link in href_links] #organiza os links dentro da variável href_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in page_links: #cria um loop para entrar em cada link dentro da variável page_links\n",
    "    ff.get(link) #abre o link\n",
    "    sleep(2) #espera carregar a página por 3 segundos\n",
    "    bs_page = bs(ff.page_source, 'html.parser') #iniciando o BeautifulSoup para analisar a página aberta pelo link\n",
    "    ID = bs_page.find('b', {'class': 'ng-binding'}).text.strip()                    #pega o ID\n",
    "    title = bs_page.find('h1', {'class': 'ng-binding'}).text.strip()                #pega o título\n",
    "    recla = bs_page.find('div', {'class': 'complain-body'}).text.strip()            #pega a reclamação\n",
    "    cidade = bs_page.findAll('li', {'class': 'ng-binding'})[0].text.strip()         #pega a cidade\n",
    "    data = bs_page.findAll('li', {'class': 'ng-binding'})[1].text.strip()           #pega a data\n",
    "    status = bs_page.find('strong', {'class': 'icon-status-text-red'}).text.strip() #pega o status\n",
    "    \n",
    "    print('ID: {}'.format(ID))            #pega o status\n",
    "    print('Titulo: {}'.format(title))     #pega o status\n",
    "    print('Reclamacao: {}'.format(recla)) #pega o status\n",
    "    print('cidade: {}'.format(cidade))    #pega o status\n",
    "    print('data: {}'.format(data))        #pega o status\n",
    "    print('status: {}'.format(status))    #pega o status\n",
    "    print('-'*40)\n",
    "    csv_writer.writerow([ID, title, recla, cidade, data, status]) #insere as informações no csv\n",
    "    \n",
    "ff.close() # fecha o navegador google chrome\n",
    "csv_file.close() # fecha o arquivo csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
